1
00:00:00,000 --> 00:00:02,220
Rowland Mosbergen: When I talk about
unconscious bias, my question

2
00:00:02,220 --> 00:00:06,960
here is does it really matter?
And my first slide, that doesn't

3
00:00:06,960 --> 00:00:10,260
work. My first slide is about
this idea that this may

4
00:00:10,260 --> 00:00:16,770
challenge you. And uncomfortable
truths is a buzzword that pops

5
00:00:16,770 --> 00:00:20,460
up from time to time. And on the
right here, you've got really

6
00:00:20,460 --> 00:00:24,720
Ruby Bridges, in 1960, when
she went to a previously white

7
00:00:24,720 --> 00:00:31,620
school, there was a black baby
doll in a coffin. And she was,

8
00:00:32,850 --> 00:00:36,150
you know, they threatened to
poison her, she's six years old.

9
00:00:37,980 --> 00:00:40,380
And she was only allowed to
bring food that she brought from

10
00:00:40,380 --> 00:00:41,730
home for her safety. And,

11
00:00:42,930 --> 00:00:46,800
and this is the challenging
thing. Because this is not this

12
00:00:46,800 --> 00:00:50,340
person is still around, she
gives talks from what I can

13
00:00:50,340 --> 00:00:55,140
remember. And you know, this is
a really, this is change is not

14
00:00:55,140 --> 00:00:58,050
something that just happens very
lightly with very minimal

15
00:00:58,050 --> 00:01:01,500
effort. And people just go, Oh,
you know what, it's okay. This

16
00:01:01,500 --> 00:01:04,230
is this is the this is what
happens when you have to when

17
00:01:04,230 --> 00:01:09,330
you bring about a change. So I
want to ask people to think

18
00:01:09,330 --> 00:01:13,530
about not writing anything down,
but to think about the bias that

19
00:01:13,530 --> 00:01:18,390
she received was a conscious or
unconscious bias. And I want

20
00:01:18,390 --> 00:01:23,490
people to think about that for a
few seconds. And then I'm going

21
00:01:23,490 --> 00:01:31,980
to give my take. So you get a
six year old, people are

22
00:01:31,980 --> 00:01:35,010
threatening to kill her. Do you
think that's conscious or

23
00:01:35,010 --> 00:01:36,150
unconscious bias?

24
00:01:43,350 --> 00:01:52,020
So my take on this is, do you
think it mattered to Ruby? Do

25
00:01:52,020 --> 00:01:57,360
you think that if someone
threatened you when you were six

26
00:01:57,360 --> 00:02:00,210
years old, whether it was
conscious or unconscious?

27
00:02:00,210 --> 00:02:05,700
Do you think it would matter?
And that's the sort of question

28
00:02:05,700 --> 00:02:09,210
that I want to ask across a few
different other examples as

29
00:02:09,210 --> 00:02:13,950
well. So Tamir Rice was 12 years
old when he was killed by a

30
00:02:13,950 --> 00:02:19,500
policeman holding a replica gun.
He didn't make any verbal

31
00:02:19,500 --> 00:02:22,050
threats or pulling his gun
towards the officers. He was

32
00:02:22,050 --> 00:02:24,540
shot and killed very, very
quickly, by the time to police

33
00:02:24,540 --> 00:02:27,780
it pulled up. It was a very
short amount of time before he

34
00:02:27,780 --> 00:02:32,220
was killed. Do you think it
mattered to me if he was killed?

35
00:02:32,220 --> 00:02:35,520
Because he was? Because the
police were consciously or

36
00:02:35,520 --> 00:02:44,850
unconsciously bias? Do you think
it mattered to his family? In

37
00:02:44,850 --> 00:02:51,270
2015, just doing a search on
racism in Belgium, I just picked

38
00:02:51,270 --> 00:02:57,420
a country. There's a situation
where this person was lost the

39
00:02:57,420 --> 00:03:03,150
leg after being chased by a
police car. And on Facebook. He

40
00:03:03,150 --> 00:03:07,080
had statements about the kind
there and there's more, there's

41
00:03:07,080 --> 00:03:11,880
more where that came from? Did
it matter? Did his left leg

42
00:03:11,880 --> 00:03:16,080
feel? Did he lose his left leg?
And was it worse because it was

43
00:03:16,080 --> 00:03:17,820
conscious or unconscious bias?

44
00:03:20,880 --> 00:03:23,520
You know, when you start to
think about that, and all of a

45
00:03:23,520 --> 00:03:25,890
sudden, this idea of conscious
bias doesn't matter.

46
00:03:27,210 --> 00:03:31,080
Doesn't seem as important
anymore. To me. As a personal

47
00:03:31,080 --> 00:03:32,550
opinion, you might have a
different opinion on that.

48
00:03:35,820 --> 00:03:39,840
But I've shown you some really
obvious things. But what it does

49
00:03:39,840 --> 00:03:44,070
is it's more subtle. So this is
really this happened just

50
00:03:44,070 --> 00:03:50,340
recently with Vanessa Nakate got
cropped out from from a photo.

51
00:03:51,300 --> 00:03:56,940
And it was just bizarre when I
first saw it, I just just

52
00:03:56,940 --> 00:04:00,120
bizarre, I can't, I can't
explain it. But it can be more

53
00:04:00,120 --> 00:04:05,790
subtle. And, again, whether
you're when you're the recipient

54
00:04:05,790 --> 00:04:12,150
of this subtle bias, it can hurt
just as badly. Whether it's

55
00:04:12,150 --> 00:04:16,290
conscious or unconscious, it
doesn't really when you're the

56
00:04:16,290 --> 00:04:21,030
victim, and it doesn't really
matter. From what I could tell.

57
00:04:23,370 --> 00:04:28,500
Bias also includes people who do
similar things getting treated

58
00:04:28,500 --> 00:04:31,770
differently. So who gets
forgiven and who gets punished?

59
00:04:32,010 --> 00:04:35,400
So one of the things that I like
to teach people is to actually

60
00:04:35,400 --> 00:04:39,360
start to break down and say,
Well, can you think of another

61
00:04:39,360 --> 00:04:44,250
example where someone's been
given a very different situation

62
00:04:44,250 --> 00:04:46,890
where you know they're forgiven
or who punished so this is Brock

63
00:04:46,890 --> 00:04:53,040
Turner, who's on the left is
very famously, was treated quite

64
00:04:53,040 --> 00:04:56,880
nicely because I think the judge
recognized that he could have

65
00:04:56,880 --> 00:04:59,970
been an Olympic swimmer one day
and they thought that it might

66
00:05:00,000 --> 00:05:08,910
ruin his career if he was, you
know, treated like a person, or

67
00:05:09,060 --> 00:05:13,020
treated like a, you know, as
someone who has to bear the

68
00:05:13,770 --> 00:05:19,650
consequences of his actions. And
then you've got Diane Davis here

69
00:05:19,650 --> 00:05:24,060
who gets five years in prison
for fish for a shoe

70
00:05:24,060 --> 00:05:24,540
robbery.

71
00:05:25,530 --> 00:05:30,690
And I think you just really
shows this idea I call it side

72
00:05:30,690 --> 00:05:31,980
by side, when you actually start

73
00:05:31,980 --> 00:05:35,520
to put these examples side by
side becomes really easy to see

74
00:05:35,520 --> 00:05:41,730
who gets forgiven. And who gets
punished. This is actually

75
00:05:41,760 --> 00:05:45,720
fairly close to home, say in
Australia, in Victoria and

76
00:05:45,720 --> 00:05:51,630
Melbourne, where I live, there
was a lot of COVID happening in

77
00:05:51,630 --> 00:05:56,130
the rich and affluent areas, and
people were just breaking things

78
00:05:56,130 --> 00:06:00,420
and this guy was walking around
and you know, no people were masks

79
00:06:00,420 --> 00:06:05,130
and cafes were full. But in the
place where there wasn't that

80
00:06:05,130 --> 00:06:08,700
much COVID there were cops that
are surrounding towers, in

81
00:06:08,700 --> 00:06:14,010
effect, and they found out later
on that the the Ombudsman for I

82
00:06:14,010 --> 00:06:16,320
think it was a human rights
ombudsman actually was saying

83
00:06:16,320 --> 00:06:19,530
that, that lockdown, having
those police around the towers

84
00:06:19,530 --> 00:06:23,340
was actually a breach of human
rights. And, again, the housing

85
00:06:23,340 --> 00:06:26,520
Minister for Victoria just said,
we're not going to apologize for

86
00:06:26,520 --> 00:06:31,410
that. And again, it's like who
gets forgiven and who gets

87
00:06:31,410 --> 00:06:37,140
punished. And once you start to,
to understand that, and you can

88
00:06:37,140 --> 00:06:41,250
do what I would call a simple
discourse analysis about who

89
00:06:41,250 --> 00:06:43,290
gets forgiven or who gets
punished, it becomes really,

90
00:06:43,290 --> 00:06:48,930
really obvious where those
biases lie. And these biases are

91
00:06:48,930 --> 00:06:52,050
obstacles for people from
marginalized groups. And I

92
00:06:52,050 --> 00:06:55,230
really love this picture,
because it actually says, Well,

93
00:06:55,230 --> 00:06:57,510
actually, I'm just going to
judge you on who gets the finish

94
00:06:57,510 --> 00:07:01,050
line. And they don't actually
judge the degree of difficulty.

95
00:07:01,950 --> 00:07:04,710
And I'd also like to point out,
though, when I talk about

96
00:07:04,770 --> 00:07:09,870
intersectionality, I'm talking
about having more belonging to

97
00:07:09,870 --> 00:07:13,560
more than one marginalized
group. And so I like to think,

98
00:07:13,680 --> 00:07:18,090
well, I don't like to think that
but I think of it as a power

99
00:07:18,090 --> 00:07:22,530
function. So if you're from a,
you know, it's exponential, it's

100
00:07:22,530 --> 00:07:26,370
exponentially more difficult to
be a person from two

101
00:07:26,370 --> 00:07:28,740
marginalized groups and to be a
person from one marginalized

102
00:07:28,770 --> 00:07:32,520
group. And incidentally,
actually, I'll leave that one

103
00:07:32,520 --> 00:07:37,320
for a little bit later. That
story. So for me, when you talk

104
00:07:37,320 --> 00:07:39,750
about unconscious bias, I'm
thinking we'll actually I think

105
00:07:39,750 --> 00:07:45,510
we should send to the people who
are marginalized. So when you're

106
00:07:45,510 --> 00:07:48,810
talking about unconscious bias,
you're centering the perpetrator

107
00:07:48,810 --> 00:07:51,690
centering yourself, and I don't
think that's actually really

108
00:07:51,690 --> 00:07:54,330
helpful. And this one that was
saying is like, you know, this

109
00:07:54,330 --> 00:07:59,010
is just an easy get out, call it
cause for behavior that's bad,

110
00:07:59,010 --> 00:08:02,340
and I don't really want to be
able to sort of focus on that.

111
00:08:03,810 --> 00:08:07,260
So I think what we should be
doing is listening to the people

112
00:08:07,260 --> 00:08:10,830
who are the most marginalized in
our society, because they are

113
00:08:10,830 --> 00:08:15,330
the canaries in the coal mine.
And how comfortable they are,

114
00:08:15,330 --> 00:08:19,230
how well treated they are, is an
indication for how healthy that

115
00:08:19,230 --> 00:08:23,250
society is. So in Australia at
the moment, we are not a healthy

116
00:08:23,250 --> 00:08:29,400
society. We are not a healthy
society. And it's been like that

117
00:08:29,400 --> 00:08:33,960
for a while now. Because when
you look at the most

118
00:08:33,960 --> 00:08:36,600
marginalized people in our
society, they're treated really

119
00:08:36,600 --> 00:08:44,550
badly. And the way I like to
think of how we adjust this is

120
00:08:44,550 --> 00:08:47,130
think of a triage in our
hospitals emergency department

121
00:08:47,700 --> 00:08:49,740
has a lot of way to you don't
really need to think about it.

122
00:08:49,740 --> 00:08:52,530
But the more marginalized a
person, the more we should help

123
00:08:52,530 --> 00:08:56,310
them. Because the people who
aren't marginalized or

124
00:08:56,310 --> 00:09:00,900
marginalized very much might not
need as much help. So when you

125
00:09:00,900 --> 00:09:04,860
think about intersectionality,
and you're saying, Well, if

126
00:09:04,860 --> 00:09:07,230
you've got more than one
marginalized pediment, one

127
00:09:07,230 --> 00:09:09,960
marginalized group, it's almost
like having a heart attack you

128
00:09:09,960 --> 00:09:13,200
want to be seeing, seen and you
want to be given as much help as

129
00:09:13,200 --> 00:09:16,740
possible. If you just sort of
hurt your finger a little bit,

130
00:09:17,010 --> 00:09:19,860
you shouldn't be the one at the
front of the queue. And then the

131
00:09:19,860 --> 00:09:22,650
following two slides, I've got a
couple of graphs where I talk

132
00:09:22,650 --> 00:09:27,240
about who we're actually
listening to, based on their

133
00:09:27,240 --> 00:09:31,320
degree of difficulty. So this is
what I call the

134
00:09:31,320 --> 00:09:35,370
intersectionality spectrum. And
this degree of difficulty is

135
00:09:35,370 --> 00:09:38,280
something that I've sort of
calculated. So I'm a big fan of

136
00:09:38,280 --> 00:09:42,990
George boxes, quite all models
are wrong, but some are useful.

137
00:09:43,620 --> 00:09:46,860
And the reason I show you this
is because I know it's wrong,

138
00:09:46,980 --> 00:09:50,850
but hopefully it'll be useful.
And what we do in Australia is

139
00:09:50,850 --> 00:09:55,620
we listen to people over on this
side of the one so white males,

140
00:09:55,620 --> 00:09:59,940
white females, they they're over
represented in a lot of media.

141
00:10:00,000 --> 00:10:03,960
in leadership positions, etc,
etc. We don't listen to people

142
00:10:03,960 --> 00:10:05,010
over on this side.

143
00:10:06,540 --> 00:10:10,320
Because actually, overall, like
I said, we're we're we are a

144
00:10:10,320 --> 00:10:14,700
we're not a healthy society. And

145
00:10:14,700 --> 00:10:17,610
if you think about it from a
triage point of view, and this

146
00:10:17,610 --> 00:10:21,330
degree of difficulty is actually
calculated in a certain way, you

147
00:10:21,330 --> 00:10:24,330
can sort of see it in the
spreadsheet. But well, the way I

148
00:10:24,330 --> 00:10:26,580
see that we should do it, if we
were to do it in a triage point

149
00:10:26,580 --> 00:10:30,750
of view, where this big arrow
here is like where we listened

150
00:10:30,750 --> 00:10:34,230
to the most, that should be
actually on the other side, we

151
00:10:34,230 --> 00:10:37,710
should be centering the people
over on this side. And just a

152
00:10:37,710 --> 00:10:41,310
highlight here as well. I'm
sitting here. So I'm actually

153
00:10:41,310 --> 00:10:44,010
extremely privileged. When you
look at when I looked at people

154
00:10:44,010 --> 00:10:49,650
to my right, my, my family, my
immediate family is all to the

155
00:10:49,650 --> 00:10:52,380
right of me. I'm the most
privileged person in my family.

156
00:10:53,610 --> 00:10:56,340
And the way I think of things
is, how do I help people to the

157
00:10:56,340 --> 00:10:59,760
right of me, because I don't
necessarily need to help people

158
00:10:59,760 --> 00:11:02,940
to the left, as much as I need
to help people to the right, and

159
00:11:02,940 --> 00:11:08,640
advice center, center these
choices. But it's not just

160
00:11:08,850 --> 00:11:14,130
important to listen, we have to
show courage and act. So I

161
00:11:14,130 --> 00:11:16,830
don't, there's a couple of
things in here that I just want

162
00:11:16,830 --> 00:11:20,850
to show is what matters to
people. 

163
00:11:20,850 --> 00:11:23,040
is how you're supported.
I think we mentioned a little

164
00:11:23,040 --> 00:11:25,050
bit more about that inclusion,
it's like you know, you feel

165
00:11:25,050 --> 00:11:27,720
supported. But you have to
recognize that if you're if

166
00:11:27,720 --> 00:11:31,830
you're neutral, you're on the
side of the oppressor. Right. If

167
00:11:31,830 --> 00:11:34,020
you're neutral, the system is
not going to change, it's going

168
00:11:34,020 --> 00:11:39,630
to say, it's going to keep its
momentum. But to act to be to

169
00:11:39,630 --> 00:11:42,150
fight the system, it actually
takes courage and a willingness

170
00:11:42,150 --> 00:11:47,130
to sacrifice your privilege to
help others. So really

171
00:11:47,130 --> 00:11:50,370
interesting, the only person who
agreed to teach Ruby, the six

172
00:11:50,370 --> 00:11:53,700
year old was a white woman
called Barbara Henry. Now,

173
00:11:53,700 --> 00:11:57,360
could you imagine what Barbara
would have had to go through to

174
00:11:57,360 --> 00:11:59,700
actually do that for a whole
year, she was the only one who

175
00:11:59,700 --> 00:12:06,450
taught taught Ruby, you can
imagine going into the into the

176
00:12:06,450 --> 00:12:09,780
staff room there. And I don't
think you should have felt very

177
00:12:09,780 --> 00:12:14,940
included. And then, but the
thing is, it's an act of courage

178
00:12:14,970 --> 00:12:19,080
to be able to actually find the
system. And that's, that's not

179
00:12:19,080 --> 00:12:22,710
easy. There are many times where
I have decided that I am not

180
00:12:22,710 --> 00:12:29,850
going to fight. Because I do not
have any. I just don't have it

181
00:12:29,850 --> 00:12:36,750
in me. So I was trying to find a
quiet, I couldn't find one. So I

182
00:12:36,750 --> 00:12:42,690
stuck my brain in pologize. for
that. I'm right, you can read

183
00:12:42,690 --> 00:12:50,460
it. For me, inclusion is being
comfortable. We all say these

184
00:12:50,460 --> 00:12:53,460
things without losing my job
losing friends or damaging my

185
00:12:53,460 --> 00:12:56,970
career. And I won't talk about
this with my friends.

186
00:13:01,980 --> 00:13:08,070
Right. So here's some I always
like to end on, I think this is

187
00:13:08,070 --> 00:13:12,060
near the end is on practical
things that you can do. You can

188
00:13:12,060 --> 00:13:15,150
change your social media census
into sexually marginalized

189
00:13:15,150 --> 00:13:18,270
people. In Ghana, if you were to
encourage people from

190
00:13:18,270 --> 00:13:21,780
marginalized groups, and
identify talented people from

191
00:13:21,780 --> 00:13:25,050
marginalized groups who may not
have had the opportunity. And

192
00:13:25,050 --> 00:13:28,470
then these are ways that you can
use your privilege to step aside

193
00:13:28,470 --> 00:13:31,830
to be able to allow people to
have the opportunities that they

194
00:13:31,830 --> 00:13:36,120
missed. And if you're up for
looking at charities to change

195
00:13:36,120 --> 00:13:39,630
the systems in your
organization's and is a really

196
00:13:39,630 --> 00:13:42,330
great example. And it's
surprising how many times I've

197
00:13:42,330 --> 00:13:46,350
seen this in the music industry,
where you have someone who's got

198
00:13:46,350 --> 00:13:48,300
a lot of privilege, who's
saying, hey, if you give this

199
00:13:48,300 --> 00:13:53,430
person a chance, I will make it
worth your while. And that

200
00:13:53,430 --> 00:13:58,320
person became, you know, be able
to you know, I'd never had to

201
00:13:58,320 --> 00:14:02,250
play a small jazz club again for
Ella Fitzgerald Fitzgerald. And

202
00:14:02,250 --> 00:14:04,590
that was a sign of someone
sacrificing their privilege or

203
00:14:04,590 --> 00:14:07,560
using their privilege to provide
an opportunity for someone else.

204
00:14:07,830 --> 00:14:10,680
There was another situation I
think Fred Astaire did at

205
00:14:11,520 --> 00:14:15,240
Princeton. Well, the artist not
only known as Prince did it as

206
00:14:15,240 --> 00:14:20,070
well, but really interesting to
be able to see those things

207
00:14:20,070 --> 00:14:27,750
happening. So in summary, for
me, unconscious bias, yes, no,

208
00:14:28,590 --> 00:14:33,690
not really interested. For me,
it's about centering

209
00:14:33,690 --> 00:14:37,170
marginalized voices, and trying
to support people from

210
00:14:37,170 --> 00:14:40,230
marginalized groups to your
right in the intersectionality

211
00:14:40,230 --> 00:14:45,720
spectrum. Everything else is
sort of not going to be as

212
00:14:45,720 --> 00:14:51,270
helpful for the people who are
who are marginalized. If you

213
00:14:51,270 --> 00:14:56,460
want to know more, I recently
tried to put together a workshop

214
00:14:57,990 --> 00:15:00,300
a theoretical one called
improving the diversity,

215
00:15:00,300 --> 00:15:02,820
inclusion and simulation, which
is got some of these things in

216
00:15:02,820 --> 00:15:06,270
there. And there's some other
interesting things that are out

217
00:15:06,270 --> 00:15:09,150
there. In terms of censoring
social media, if you're on

218
00:15:09,150 --> 00:15:13,050
Twitter, I put down this list of
public it should be a public

219
00:15:13,050 --> 00:15:16,830
place of people to follow. And
these are the people that are

220
00:15:16,860 --> 00:15:21,750
sort of high frequency tweeters
probably going to take you out

221
00:15:21,750 --> 00:15:27,840
of your comfort zone if it's not
already, who I use as my gauge,

222
00:15:28,230 --> 00:15:33,000
and have really sort of followed
when I've started followings.

223
00:15:34,260 --> 00:15:37,590
When I've started following
marginalized voices, I learned

224
00:15:37,590 --> 00:15:41,370
way more than I've learned
anywhere else. But there's a

225
00:15:41,370 --> 00:15:44,460
price to be paid. When I was
talking about this to someone

226
00:15:44,490 --> 00:15:48,780
the other day, she said, Yeah,
I've noticed that I've learned a

227
00:15:48,780 --> 00:15:54,570
lot more, but I'm way more sad
than I was before. Because a lot

228
00:15:54,570 --> 00:15:59,400
of these stories of marginalized
people are either not they're

229
00:15:59,400 --> 00:16:05,190
not happy stories. But you have
to go through that process to be

230
00:16:05,190 --> 00:16:08,490
able to come out the other end
and say, Well, actually, it

231
00:16:08,490 --> 00:16:13,440
gives me motivation to keep
doing these sorts of things to

232
00:16:13,440 --> 00:16:19,980
bring about change. So I think
that is it. So I don't know what

233
00:16:19,980 --> 00:16:20,760
happens now.

